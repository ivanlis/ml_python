{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-forward NN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: Deep Learning with TensorFlow, Md. Rezaul Karim, Giancarlo Zaccone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a3c17564932f>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ivan/learning/datascience_workspace/py36virt/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ivan/learning/datascience_workspace/py36virt/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/digits/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ivan/learning/datascience_workspace/py36virt/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/digits/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ivan/learning/datascience_workspace/py36virt/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/digits/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/digits/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ivan/learning/datascience_workspace/py36virt/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataPath = \"data/digits\"\n",
    "if not os.path.exists(dataPath):\n",
    "    os.makedirs(dataPath)\n",
    "inputData = input_data.read_data_sets(dataPath, one_hot = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_asdict',\n",
       " '_fields',\n",
       " '_make',\n",
       " '_replace',\n",
       " '_source',\n",
       " 'count',\n",
       " 'index',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(inputData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of arrays:\n",
      "training images: (55000, 784), training labels: (55000, 10),\n",
      "testing images: (10000, 784), testing labels: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes of arrays:\\ntraining images: {}, training labels: {},\\ntesting images: {}, testing labels: {}\".format(\n",
    "    inputData.train.images.shape, inputData.train.labels.shape, \n",
    "    inputData.test.images.shape, inputData.test.labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image0 = np.resize(inputData.train.images[0], (28, 28))\n",
    "label0 = inputData.train.labels[0]\n",
    "label0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADZxJREFUeJzt3X+IHPUZx/HPkx9VuFRMGnMETbUt0lBPSMsRK2o5sSkqxRj/iFEoKZaeQhMrKjRaSAOCaOkPCmLxiqGxJDZKW5M/qq0NjT+wiLlo/d2q9RovXhIlEg1iYuLTP24sp958Z92d3Zm95/2C43bnmR8Pm3xuZnd25mvuLgDxTKu6AQDVIPxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ka0cmNmRlfJwTazN2tkfla2vOb2flm9i8ze9nM1rSyLgCdZc1+t9/Mpkv6t6QlkkYlPSHpMnd/PrEMe36gzTqx518s6WV3/4+7H5b0e0lLW1gfgA5qJfwnSnptwvPRbNpHmNmgme0wsx0tbAtAydr+gZ+7D0kakjjsB+qklT3/bkkLJjw/KZsGoAu0Ev4nJJ1qZl8ws89IWiFpazltAWi3pg/73f2Ima2S9BdJ0yWtd/fnSusMQFs1faqvqY3xnh9ou458yQdA9yL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqKaH6JYkMxuR9I6ko5KOuHt/GU0BaL+Wwp85193fLGE9ADqIw34gqFbD75L+ambDZjZYRkMAOqPVw/6z3X23mc2T9KCZvejuD0+cIfujwB8GoGbM3ctZkdk6SQfd/WeJecrZGIBc7m6NzNf0Yb+Z9ZjZZz98LOlbkp5tdn0AOquVw/5eSX8ysw/Xs8ndHyilKwBtV9phf0Mb47AfaLu2H/YD6G6EHwiK8ANBEX4gKMIPBEX4gaDKuKoPFbv++utza0Wnct98M31BZl9fX7L+yCOPJOtbt25N1lEd9vxAUIQfCIrwA0ERfiAowg8ERfiBoAg/ENSUuaR39erVyfoZZ5yRrF9yySVlttNRxxxzTNPLFv37T58+PVl///33k/UjR47k1nbt2pVcdmBgIFnfs2dPsh4Vl/QCSCL8QFCEHwiK8ANBEX4gKMIPBEX4gaC66jz/pk2bcmuXXnppctlp0/g7121efPHFZP28885L1l9//fUy2+kanOcHkET4gaAIPxAU4QeCIvxAUIQfCIrwA0EVnuc3s/WSvi1pn7v3ZdPmSNos6RRJI5KWu/tbhRtr8Tz/gQMHcmvHHXdcctmic76HDx9uqqcyPPbYY8n65s2bO9TJp3fBBRck6ytWrMitHX/88S1tu+h7AOeee25ubSrfC6DM8/y/lXT+x6atkbTN3U+VtC17DqCLFIbf3R+WtP9jk5dK2pA93iDp4pL7AtBmzb7n73X3sezxHkm9JfUDoENaHqvP3T31Xt7MBiUNtrodAOVqds+/18zmS1L2e1/ejO4+5O797t7f5LYAtEGz4d8qaWX2eKWkLeW0A6BTCsNvZndL+oekL5vZqJl9T9ItkpaY2UuSvpk9B9BFuup6/tNPPz23VnRf/nvvvTdZT32HAM1buHBhbu2hhx5KLjtv3ryWtn3rrbfm1tasmbpnp7meH0AS4QeCIvxAUIQfCIrwA0ERfiCorjrVh6llcDD9re877rijpfW/++67ubWenp6W1l1nnOoDkET4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQbU8XBeQsnbt2tzaOeec09Ztz5iR/997YGAguez27dvLbaaG2PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCF9+03s/WSvi1pn7v3ZdPWSfq+pDey2W509z8Xboz79rfFggULcmurV69OLnvVVVeV3c5HzJo1K7dm1tDt5dvi0KFDyfqxxx7boU7KV+Z9+38r6fxJpv/S3RdlP4XBB1AvheF394cl7e9ALwA6qJX3/KvM7GkzW29ms0vrCEBHNBv+X0v6kqRFksYk/TxvRjMbNLMdZrajyW0BaIOmwu/ue939qLt/IOk3khYn5h1y935372+2SQDlayr8ZjZ/wtNlkp4tpx0AnVJ4Sa+Z3S1pQNJcMxuV9BNJA2a2SJJLGpF0ZRt7BNAGheF398smmXxnG3oJa/ny5cn64sW576okSVdccUVubfZsPoudzH333Vd1C5XjG35AUIQfCIrwA0ERfiAowg8ERfiBoLh1dwn6+vqS9XvuuSdZX7hwYbLezktfDxw4kKwfPHiwpfXfcMMNubWiy2pvu+22ZP2EE05oqidJ2rVrV9PLThXs+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqMJbd5e6sS6+dffNN9+cW7vyyvTtDObMmZOsHz58OFkvOh9+++2359ZGR0eTy95///3J+iuvvJKst9PIyEiyfvLJJyfrqdftzDPPTC775JNPJut1VuatuwFMQYQfCIrwA0ERfiAowg8ERfiBoAg/EBTX8zdoYGAgt1Z0Hn94eDhZv+mmm5L1LVu2JOvd6qyzzkrW586d29L6jx49mlvr5vP4ZWHPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBFZ7nN7MFku6S1CvJJQ25+6/MbI6kzZJOkTQiabm7v9W+Vqt10UUX5dbWrl2bXPbqq68uu50p4bTTTkvWe3p6Wlr/zp07W1p+qmtkz39E0nXu/hVJX5f0AzP7iqQ1kra5+6mStmXPAXSJwvC7+5i778wevyPpBUknSloqaUM22wZJF7erSQDl+1Tv+c3sFElflfS4pF53H8tKezT+tgBAl2j4u/1mNkvSHyRd4+5vTxw/zt097/58ZjYoabDVRgGUq6E9v5nN1HjwN7r7H7PJe81sflafL2nfZMu6+5C797t7fxkNAyhHYfhtfBd/p6QX3P0XE0pbJa3MHq+UNDUvPQOmqMJbd5vZ2ZIekfSMpA+yyTdq/H3/PZI+L+m/Gj/Vt79gXV17626Ub+PGjcn65Zdfnqy/9957yfqyZctyaw888EBy2W7W6K27C9/zu/ujkvJWdt6naQpAffANPyAowg8ERfiBoAg/EBThB4Ii/EBQ3LobbTU2NpZbmzdvXkvrLrpkdyqfyy8De34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrz/Gir1PDl06al9z1F1+sXDW2ONPb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU5/nRklWrViXrM2bk/xc7dOhQctlrr702Wed6/daw5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoMzd0zOYLZB0l6ReSS5pyN1/ZWbrJH1f0hvZrDe6+58L1pXeGGpn5syZyfqrr76arPf29ubWtm/fnlx2yZIlyTom5+7WyHyNfMnniKTr3H2nmX1W0rCZPZjVfunuP2u2SQDVKQy/u49JGssev2NmL0g6sd2NAWivT/We38xOkfRVSY9nk1aZ2dNmtt7MZucsM2hmO8xsR0udAihVw+E3s1mS/iDpGnd/W9KvJX1J0iKNHxn8fLLl3H3I3fvdvb+EfgGUpKHwm9lMjQd/o7v/UZLcfa+7H3X3DyT9RtLi9rUJoGyF4Tczk3SnpBfc/RcTps+fMNsySc+W3x6Admnk0/6zJH1H0jNm9lQ27UZJl5nZIo2f/huRdGVbOkSlik4Fb9q0KVkfHh7OrW3evLmpnlCORj7tf1TSZOcNk+f0AdQb3/ADgiL8QFCEHwiK8ANBEX4gKMIPBFV4SW+pG+OSXqDtGr2klz0/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTV6SG635T03wnP52bT6qiuvdW1L4nemlVmbyc3OmNHv+TziY2b7ajrvf3q2ltd+5LorVlV9cZhPxAU4QeCqjr8QxVvP6WuvdW1L4nemlVJb5W+5wdQnar3/AAqUkn4zex8M/uXmb1sZmuq6CGPmY2Y2TNm9lTVQ4xlw6DtM7NnJ0ybY2YPmtlL2e9Jh0mrqLd1ZrY7e+2eMrMLK+ptgZn93cyeN7PnzOyH2fRKX7tEX5W8bh0/7Dez6ZL+LWmJpFFJT0i6zN2f72gjOcxsRFK/u1d+TtjMviHpoKS73L0vm/ZTSfvd/ZbsD+dsd/9RTXpbJ+lg1SM3ZwPKzJ84srSkiyV9VxW+dom+lquC162KPf9iSS+7+3/c/bCk30taWkEftefuD0va/7HJSyVtyB5v0Ph/no7L6a0W3H3M3Xdmj9+R9OHI0pW+dom+KlFF+E+U9NqE56Oq15DfLumvZjZsZoNVNzOJ3mzYdEnaI6m3ymYmUThycyd9bGTp2rx2zYx4XTY+8Puks939a5IukPSD7PC2lnz8PVudTtc0NHJzp0wysvT/VfnaNTviddmqCP9uSQsmPD8pm1YL7r47+71P0p9Uv9GH9344SGr2e1/F/fxfnUZunmxkadXgtavTiNdVhP8JSaea2RfM7DOSVkjaWkEfn2BmPdkHMTKzHknfUv1GH94qaWX2eKWkLRX28hF1Gbk5b2RpVfza1W7Ea3fv+I+kCzX+if8rkn5cRQ85fX1R0j+zn+eq7k3S3Ro/DHxf45+NfE/S5yRtk/SSpL9JmlOj3n4n6RlJT2s8aPMr6u1sjR/SPy3pqeznwqpfu0RflbxufMMPCIoP/ICgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBPU/uUhluG6K4TwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image0, cmap = 'Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture (5 levels sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 1: sigmoid, L = 200 neurons\n",
    "\n",
    "Layer 2: sigmoid, M = 100 neurons \n",
    "\n",
    "Layer 3: sigmoid, N =  60 neurons \n",
    "\n",
    "Layer 4: sigmoid, O =  30 neurons \n",
    "\n",
    "Layer 5: softmax,      10 neurons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsPath = 'logs/sigmoid5'\n",
    "batchSize = 100\n",
    "learningRate = 0.003\n",
    "trainingEpochs = 10\n",
    "displayEpoch = 1\n",
    "imageWidth = 28\n",
    "\n",
    "numOutputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float64, shape = [None, imageWidth * imageWidth], name = 'InputData')\n",
    "XX = tf.reshape(X, [-1, imageWidth * imageWidth])\n",
    "Y_ = tf.placeholder(tf.float64, [None, numOutputs], name = 'LabelData') # 10 classes: digits 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 200\n",
    "M = 100\n",
    "N =  60\n",
    "O =  30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 1 weights: from imageWidth * imageWidth inputs to L neurons\n",
    "\n",
    "Level 1 bias: one for each of the L neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(dtype = tf.float64, initial_value = \n",
    "                 tf.truncated_normal(dtype = tf.float64, shape = [imageWidth * imageWidth, L], stddev = 0.1))\n",
    "B1 = tf.Variable(dtype = tf.float64, initial_value = tf.zeros(dtype = tf.float64, shape = [L]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = tf.nn.sigmoid(tf.matmul(XX, W1) + B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(dtype = tf.float64, \n",
    "                 initial_value = tf.truncated_normal(dtype = tf.float64, shape = [L, M], stddev = 0.1))\n",
    "B2 = tf.Variable(initial_value = tf.zeros(dtype = tf.float64, shape = [M]))\n",
    "Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(initial_value = tf.truncated_normal(dtype = tf.float64, shape = [M, N], stddev = 0.1))\n",
    "B3 = tf.Variable(initial_value = tf.zeros(dtype = tf.float64, shape = [N]))\n",
    "Y3 = tf.nn.sigmoid(tf.matmul(Y2, W3) + B3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(initial_value = tf.truncated_normal(dtype = tf.float64, shape = [N, O], stddev = 0.1))\n",
    "B4 = tf.Variable(initial_value = tf.zeros(dtype = tf.float64, shape = [O]))\n",
    "Y4 = tf.nn.sigmoid(tf.matmul(Y3, W4) + B4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 5 (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W5 = tf.Variable(initial_value = tf.truncated_normal(dtype = tf.float64, shape = [O, numOutputs], stddev = 0.1))\n",
    "B5 = tf.Variable(tf.ones(dtype = tf.float64, shape = [numOutputs]))\n",
    "Ylogits = tf.matmul(Y4, W5) + B5\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function: the cross-entropy between the target and the softmax activation function output (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossEntropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = Ylogits, labels = Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "costOp = tf.reduce_mean(crossEntropy) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctPrediction = tf.equal(tf.argmax(Y, axis = 1), tf.argmax(Y_, axis = 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPrediction, tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOp = tf.train.AdamOptimizer(learningRate).minimize(costOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summaries for TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar(\"cost\", costOp)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "summaryOp = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "initOp = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Optimization finished.\n",
      "Accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(initOp)\n",
    "    writer = tf.summary.FileWriter(logsPath, graph = tf.get_default_graph())\n",
    "    \n",
    "    for epoch in range(trainingEpochs):\n",
    "        batchCount = int(inputData.train.num_examples / batchSize)\n",
    "        for i in range(batchCount):\n",
    "            batchX, batchY = inputData.train.next_batch(batchSize)\n",
    "            _, summary = sess.run([trainOp, summaryOp], feed_dict = {X: batchX, Y_: batchY})\n",
    "            writer.add_summary(summary, epoch * batchCount + i)\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "    print(\"Optimization finished.\")\n",
    "\n",
    "    print(\"Accuracy: {}\".format(accuracy.eval(feed_dict = {X: inputData.test.images, Y_: inputData.test.labels})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
