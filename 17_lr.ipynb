{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression on the Housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: Deep Learning with TensorFlow, Md. Rezaul Karim, Giancarlo Zaccone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import genfromtxt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readBostonData():\n",
    "    boston = load_boston()\n",
    "    features = np.array(boston.data)\n",
    "    labels = np.array(boston.target)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(dataset):\n",
    "    mu = np.mean(dataset, axis = 0)\n",
    "    sigma = np.std(dataset, axis = 0)\n",
    "    return (dataset - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biasVector(features, labels):\n",
    "    return np.concatenate((np.ones((features.shape[0], 1), dtype = np.float64), \n",
    "                           features), axis = 1), labels[:, np.newaxis]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = readBostonData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedFeatures = normalizer(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: (506, 14), label: (506, 1)\n"
     ]
    }
   ],
   "source": [
    "data, label = biasVector(normalizedFeatures, labels)\n",
    "print(\"data: {}, label: {}\".format(data.shape, label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX: (379, 14), testX: (127, 14), trainY: (379, 1), testY: (127, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(data, label, test_size = 0.25, random_state = 100)\n",
    "print(\"trainX: {}, testX: {}, trainY: {}, testY: {}\".format(\n",
    "    trainX.shape, testX.shape, trainY.shape, testY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.01\n",
    "trainingEpochs = 100000\n",
    "logLoss = np.empty(shape = (1,), dtype = np.float64)\n",
    "nDim = data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float64, (None, nDim))\n",
    "Y = tf.placeholder(tf.float64, (None, 1))\n",
    "W = tf.Variable(tf.ones((nDim, 1), dtype = tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.matmul(X, W)\n",
    "costOp = tf.reduce_mean(tf.square(y_ - Y))\n",
    "trainingStep = tf.train.GradientDescentOptimizer(learningRate).minimize(costOp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossValues = []\n",
    "for epoch in range(trainingEpochs):\n",
    "    sess.run(trainingStep, feed_dict = {X: trainX, Y: trainY})\n",
    "    lossValues.append(sess.run(costOp, feed_dict = {X: trainX, Y: trainY}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(range(len(lossValues)), lossValues)\n",
    "ax.grid(True)\n",
    "ax.set_xlim(0, 1000)\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = sess.run(y_, feed_dict = {X: testX})\n",
    "mse = tf.reduce_mean(tf.square(predY - testY))\n",
    "mseValue = sess.run(mse)\n",
    "print('MSE on the test set: {}'.format(mseValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.scatter(testY, predY)\n",
    "ax.plot((testY.min(), testY.max()), (testY.min(), testY.max()), 'k--')\n",
    "ax.set_xlabel('Measured'); ax.set_ylabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
